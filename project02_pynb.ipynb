{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "XcoDxJK_TspT"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community pypdf -q langchain_google_genai  langchain_chroma -q\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  --upgrade -q google-auth google-auth-oauthlib google-auth-httplib2  google-cloud"
      ],
      "metadata": {
        "id": "ypWJsCQomgDW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY_3')\n"
      ],
      "metadata": {
        "id": "zrQwdPPjxPBc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/proj.json\"\n"
      ],
      "metadata": {
        "id": "ujiIdNQ9x5gv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:1 pdf loading."
      ],
      "metadata": {
        "id": "d3YOn6iWz896"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/somatosensory.pdf\")\n",
        "data = loader.load()\n"
      ],
      "metadata": {
        "id": "aiCl1hVAxPqb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnjxfOrMxYLb",
        "outputId": "2b08d3b6-0a89-42c3-db83-6b35d8b8d1cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:2 splitting the data of pdf file."
      ],
      "metadata": {
        "id": "xBlM06an0V9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=500)\n",
        "docs = text_splitter.split_documents(data)\n",
        "\n",
        "\n",
        "print(\"total number of documents : \" ,len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXV6oTl10drQ",
        "outputId": "795691a6-2b04-4a49-d408-8d750b29370c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of documents :  13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:4 creating embedding of the data."
      ],
      "metadata": {
        "id": "TWugYMIP2aql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_chroma import Chroma\n"
      ],
      "metadata": {
        "id": "dC_slc_J0zEV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_Model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\" , google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "s4xqxAYW2CPA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:5 Embedding data and retriver."
      ],
      "metadata": {
        "id": "o1I9VLEe26qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=docs, embedding=embedding_Model)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
        "\n"
      ],
      "metadata": {
        "id": "KiKOxHmP2dSR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:6 creating llm model."
      ],
      "metadata": {
        "id": "L__-nxnJ3sBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash-exp\" , temperature = 0.3 , max_tokens=1000)"
      ],
      "metadata": {
        "id": "WFx1_w1q3eNF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:7 defining user prompt."
      ],
      "metadata": {
        "id": "KdgcEWJb399M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "wUad66bg4Ito"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:8 creating chain"
      ],
      "metadata": {
        "id": "UNi7F6RI4N9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "CHVlLFT74ZlU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:9 asking question not included in pdf."
      ],
      "metadata": {
        "id": "EdIR3hXZ4i9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\" : \"what is k2\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_085USpB40ow",
        "outputId": "6a3e049d-14d4-41de-89d3-095ec786ca08"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but the provided text does not contain any information about \"k2\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step:10 asking questions included in pdf ."
      ],
      "metadata": {
        "id": "uZqJIUtA5BNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\" : \"what is somatosensory\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZnyWxKd5EuT",
        "outputId": "7aec1c6e-1441-4970-ef35-f24b01cb785c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The somatosensory system consists of sensors in the skin and sensors in our muscles, tendons, and joints. The receptors in the skin tell us about temperature, pressure and surface texture, and pain. The receptors in muscles and joints provide information about muscle length, muscle tension, and joint angles.\n"
          ]
        }
      ]
    }
  ]
}